# Кластеризация

**Кластеризация** — это неуправляемый метод машинного обучения, который группирует объекты в наборы (кластеры) так, чтобы объекты внутри одного кластера были более похожи друг на друга, чем на объекты из других кластеров.

Необходимо выбрать метрику расстояния (например, евклидово, манхэттенское) для измерения сходства между объектами.

Необходимо выбрать алгоритм, который последовательно распределяет объекты по кластерам, минимизируя внутрикластерное разбросание и/или максимизируя межкластерное различие.

Наиболее популярные типы алгоритмов кластеризации:

- Центроидные (prototype-based). Пример алгоритма: **k-means** минимизирует сумму квадратов расстояний до центров кластеров. Быстрый и простой, но требует заранее задать k, чувствителен к выбросам и масштабу признаков
- Иерархические. Пример алгоритма: Divisive clustering (дивизивная) - начинает со всех точек и рекурсивно делит.
Плюс: можно не фиксировать число кластеров заранее (выбирают «срез» дендрограммы). Минус: на больших выборках может быть тяжёлой по памяти/времени
- Плотностные. Пример алгоритма - DBSCAN: кластеры как области высокой плотности + выделение шума/выбросов. Хорош для «не-сферических» кластеров, но чувствителен к параметрам eps и min_samples, хуже при сильно разной плотности
- Модельные (вероятностные). Пример алгоритма: Байесовские смеси (Dirichlet Process Mixture) - могут автоматически подбирать число кластеров (в рамках модели), но сложнее и тяжелее
- Графовые / спектральные. Пример алгоритма: Spectral clustering - строит граф похожести и кластеризует в спектральном представлении (через собственные векторы лапласиана). Хорош для сложной структуры, но дорог по вычислениям на больших n.
- Прочие: Mean Shift, Affinity Propagation, BIRCH
