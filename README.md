# Краткие заметки о машинном обучении

Задача данного репозитария - подготовить заметки, помогающие решать тестовые задачи на курсах обучения машинному обучению. В качестве языка программирования планируется использовать Python.

Основной инструмент работы - [Google Colab](https://colab.research.google.com/#), одно из ключевых преимуществ которого состоит в том, что он позволяет в удобном форме обмениваться "блокнотами" (.ipynb) - документами, которые совмещают в себе текстовые комментарии, формулы и код на Python, что делает его очень удобным при обмене данными между преподавателем и студентами. Также Colab позволяет избежать сложной настройки среды исполнения, автоматически доустанавливая необходимые для работы пакеты (packages).

У Google Colab отличная интеграция с Google Drive, которая позволяет сохранять .ipynb-файлы на Drive, и использовать Drive для запуска виртуальной машины Google Colab.

## Получение данных в виртуальной машине Colab

Одним из популярных источников данных для изучения ML является репозитарий **Kaggle Datasets**.

Для изучения ML также очень часто используются Dataset-ы из [SKLearn](https://scikit-learn.org/stable/).

В случае использования Google Colab загружать данные можно следующим кодом:

```py
import pandas as pd

# Загружаем данные в Pandas DataFrame
df = pd.read_csv('your_file.csv')
print(df.head())
```

Загрузка данных осуществляется в объект типа DataFrame.

В CSV-файле, первая строка обычно содержит именя колонок таблицы. Мы можем загрузить не весь документ, а только указанные колонки, например:

```py
df = pd.read_csv("pokemon.csv", index_col = "Pokemon")
```

Если нам нужно работать только с одной колонкой, то мы можем загрузить её не в DataFrame, а в Series, указав параметр `squeeze = True`. Пример:

```py
df = pd.read_csv("pokemon.csv", index_col = "Pokemon", squeeze = True)
```

Если необходимо получить данные типа "дата", то следует явным образом указать имя поля, используя параметр `parse_dates`:

```py
pd.read_csv(
    "revolutionary_war.csv",
    index_col = "Start Date",
    parse_dates = ["Start Date"]
)
```

Список импортируемых столбов можно указать используя параметр usecols:

```py
pd.read_csv(
    "revolutionary_war.csv",
    index_col = "Start Date",
    parse_dates = ["Start Date"],
    usecols = ["State", "Start Date"],
    squeeze = True
)
```

### Использование коллекций Kaggle

Если потребуется загружать данные из Kaggle на локальную машину, то может потребоваться получить ключ API, загружать и распаковывать архив.

Загрузить данные в Colab с локального диска можно следующим образом:

```py
from google.colab import files

# Загрузка файла
uploaded = files.upload()

# Выводим названия загруженных файлов
for filename in uploaded.keys():
    print(f'Файл загружен: {filename}')
```

Если необходимо сохранить файл под конкретным именем, то его может потребоваться переименовать.

Указать кодировку (encoding) данных можно используя дополнительный параметр:

```py
df = pd.read_csv('имя_вашего_файла.csv', encoding='utf-8') 
```

Также можно указать символ-разделитель при разборе CSV-файла:

```py
df = pd.read_csv('имя_вашего_файла.csv', sep=';')
```

Также можно подключить достут к Google Drive из виртуальной машины Colab:

```py
from google.colab import drive
import pandas as pd

# Подключение Google Диска
drive.mount('/content/drive')

# Чтение CSV файла с Google Диска
df = pd.read_csv('/content/drive/MyDrive/MyFolder/data.csv')
print(df.head())
```

Однако в этом случае необходимо предоставить права доступа.

## Ключевые библиотеки ML для Python

- numpy - реализация математических функций, таких как: linspace(), sin(), random()
- matplotlib - визуализация данных в виде графиков
- Pandas - импорт данных из разных источников (например, CSV-файлов), формирование выборок данных

## Pandas

Официальная документация библиотеки доступна [здесь](https://pandas.pydata.org/docs/)

Курсы по Pandas на Udemy: [Борис Пасхавер](https://www.udemy.com/user/borispaskhaver/)

Официальный репозиторий на [Github](https://github.com/pandas-dev/pandas)

Установить Pandas можно посредством [репозитария PyPi](https://pepy.tech/projects/pandas)

Уэс Маккини: "Эмперическое правильно для Pandas: оперативной памяти должно быть в 5-10 раз больше, чем объём набора данных".

Конкуренты Pandas: язык R (Хэдли Викхэм) и SAS от SAS Institute.

Для изучения Pandas часто используются блокноты Jupyter. Набор готовых блокнотов от Бориса Пасхавера доступен [здесь](https://github.com/paskhaver/pandas-in-action)

Типовой импорт Pandas:

```py
import pandas as pd
```

Чтения данных из файла:

```py
pd.read_csv("movies.csv")
```

При загрузке данных мы можем указать имя поля, которое является уникальным индексом:


```py
pd.read_csv("movies.csv", index_col="Title")
```

Библиотека Pandas использует два основных типа объектов:

- DataFrame - для хранения наборов данных с несколькими столбцами. Условно, это аналог таблицы Excel
- Series - для хранения наборов данных из одного столбца. Series представляет собой одномерный маркированный массив однородных данных. Термин "однородный" означает, что все значения серии - одного типа. Каждому значению Serias в Pandas соответствует метка (label) - идентификатор, с помощью которого можно ссылаться на это значение. Данные в Series являются упорядоченными. Отчёт начинается с нуля. Series - одномерная структура данных

Извлечь первые несколько строк можно командой: `movies.head(4)`

Извлечь последние несколько строк можно командой: `movies.tail(6)`

Получить информацию о наборе данных в DataFrame: `movies.shape`

Общее количество ячеек: `movies.size`

Запросить типы данных столбцов DataFrame: `movies.dtypes`

Получить одну строку по индексу можно с помощью iloc:

```py
movies.iloc[499]            # По индексу
movies.loc["Forrest Gump"]  # По метке индекса
```

Сортировка по значению:

```py
movies.sort_values(by=["Studio","Year"]).head()
movies.sort_index().head()
```

Часто нам приходится выполнять некоторые действия по одной колонке. Данные из одной колонки называются Series. Получить объект типа Series можно из DataFrame: `movies["Studio"]`. Например, мы можем выбрать колонку и подсчитать количество уникальных значений в ячейках этой серии:

```py
movies["Studio"].value_counts().head(10)
```

Чтобы отобрать из DataFrame данные по конкретной колонке, можно использовать конструкцию:

```py
release_by_universal = (movies["Studio"] == "Universal")
movies[release_by_universal].head()
```

Можно использовать несколько условий:

```py
released_in_2015 = (movies["Year"] == 2015)
movies[release_by_universal & released_in_2015]
```

Мы можем использовать разные логические операторы, в том числе `&` и `|`

Можно задавать и более сложные условия отбора, например:

```py
before_1975 = movies["Year"] < 1975
movies[before_1975]
```

Или:

```py
mid_8os = movies["Year"].between(1983, 1986)
movies[mid_8os]
```

Для фильтрации данных можно использовать и текстовые индексы:

```py
has_dark_in_title = movies.index.str.lower().str.contains("dark")
movies[has_dark_in_title]
```

>Важно понимать, что когда мы вызываем функции фильтрации, они просто формируют выборку, которую затем можно использовать в качестве индексатора `[]` DataFrame для получения некоторого подмножества DataFrame.

## Группировка данных. Агрегация

Для выполнения группировки может потребоваться выполнять чистку данных, например:

```py
movies["Gross"].str.replace("$", "", regedx = False).str.replace(",", "", regex = False)
```

Преобразовать тип из строчного, например, к вещественному можно используя метод **astype**():

```py
movies["Gross"].str.replace("$", "", regedx = False).str.replace(",", "", regex = False).astype(float)
```

Зафиксировать преобразование в DataFrame можно используя круглые скобки `(выборка)`:

```py
movies["Gross"] = (movies["Gross"].str.replace("$", "", regedx = False).str.replace(",", "", regex = False).astype(float))
```

К выполненному преобразованию можно применять различные операции, такие как **mean**():

```py
movies["Gross"].mean()
```

Группировка выполняется созданием нового объекта:

```py
studios = movies.groupby("Studio")
```

Затем уже к сгруппированным данным можно применять различные операции, например - посчитать количество элементов по каждой группе:

```py
studio["Gross"].count().head()
```

Подсчитанные результаты можно отсортировать:

```py
studio["Gross"].count().sort_values(ascending = False).head()
```

Или можно поситать сумму, используя функцию **sum**():

```py
studio["Gross"].sum().sort_values(ascending = False).head()
```

## Series

Создать пустую серию можно с помощью конструктора без параметров: `pd.Series()`. Создать серию с данными можно так:

```py
ice_cream_flavors = [
    "Chocolate",
    "Vanilla",
    "Strawberry",
    "Rum Raisin"
]
pd.Series(ice_cream_flavors)
```

В качестве входных значений конструктора могут использоваться: списки, ассоциативные массивы, кортежи, NumPy-объекты ndarray, и т.д.

Серия состоит из индекса и данных. Индекс начинается с нуля и по умолчанию индекс - это просто числа. Но мы можем задать для каждого индекса символическое имя, например:

```py
ice_cream_flavors = [
    "Chocolate",
    "Vanilla",
    "Strawberry",
    "Rum Raisin"
]

days_of_week = ("Monday", "Wednesday", "Friday", "Saturday")

pd.Series(data = ice_cream_flavors, index = days_of_week)
```

>Типы `int64` и `float64` занимают в памяти 8 байт. 

Pandas сам определяет тип данных. Однако мы может задать тип явным образом, например:

```py
lucky_numbers = [4, 8, 15, 16, 23, 42]
pd.Series(lucky_numbers, dtype = "float")
```

### NaN

nan = not a number, условный объект, обзначающий пустое или отсутствующее значение. Определён в NumPy и часто выглядит как `np.nan`:

```py
temperatures = [94, 88, np.nan, 91]
pd.Series(data = temperatures)
```

## Создание объектов Series из объектов Python

Пример:

```py
calorie_info = {
    "Cereal": 125,
    "Chocolate Bar": 406,
    "Ice Cream Sundae": 342
}
diet = pd.Series(calorie_info)
```

Создавать серии можно из из кортежей:

```py
pd.Series(data = ("Red", "Green", "Blue"))

rgb_colors = [(120, 41, 26), (196, 165, 45)]
pd.Series(data = rgb_colors)
```

Так же можно проинициализировать серию объектом типа **ndarray**, входящего в состав NumPy. Таким массивы применяются во множестве библиотек для исследования данных, это очень распространённый формат хранения данных для последующего перемещения.

Пример создания и перемещения данных в Pandas:

```py
random_data = np.random.randint(1, 101, 10)
pd.Series(random_data)
```

Посмотреть тип данных можно используя встроенную функцию type():

```py
type(diet.values)
```

Pandas делегируем ответственность за хранение значений Series объекту из другой библиотеки. Это абсолютно нормально для мира ML. NumPy - одна из зависимостей Pandas. Объект ndarray оптимизирован по скорость и эффективности за счёт того, что написан на языке программирования Си.

Более подробную информацию об объекте Pandas можно увидеть так: `diet.dtype`

Размерность данных можно получить используя `diet.shape`

Чтобы представить кортеж, в Python часто добавляют запятую после значения, например: `(3,)`

Для трассировки данных удобно использовать функции head(n) и tail(n).

## Транслирование / Broadcasting

NumPy позволяет применить одну и ту же операцию ко всем значениям объекта Series. Этот механизм называется "транслированием". Пример применения broadcasting-а:

```py
s1 = pd.Series([1,2,3], index=["A","B","C"])
s2 = pd.Series([4,5,6], index=["A","B","C"])
s1 + s2
```

В приведённом выше примере будет выполнено сложение элементов Series с одинаковыми индексами, т.е. результатом вычисления будет `[5,7,9]`

Преобразовать объект типа Series в обычный список можно командой `list(s1)`, а в словарь - `dict(s1)`. Таким образом обеспечивается "бесшовная" интеграция типов Pandas/NumPy и стандартных типов Python.

## Вывов функции для каждого элемента Series

Предположим, что у нас есть объект типа Series под именем google. Мы можем вызвать функцию round() для каждого элемента серии:

```py
google.apply(round)
```

Вызов apply() возвращает новый экземпляр Series.

## DataFrame

DataFrame - это аналог Excel-таблицы, т.е. он работает в двух измерениях. Инициализация DataFrame может выглядеть следующим образом:

```py
city_data = {
    "City": ["New York City", "Paris", "Barcelona", "Rome"],
    "Country": ["United States", "France", "Spain", "Italy"],
    "Population": [8600000, 2141000, 5515000, 2873000]
}

cities = pd.DataFrame(city_data)
```

Развернуть таблицу можно используя функцию transpose:

```py
cities.transpose()
```

либо `cities.T`

Получить тип данных серии можно командой: `pd.Series([1,2,3])/dtype`, а для DataFrame можно получить тип каждой колонки: `nba.dtypes`. Список всех колонок доступен с помощью вызова: `nba.columns`. Размерность объёкта Pandas: `nba.ndim`.

Вызов `nba.share` возвращает размеры объекта DataFrame по измерениям в виде кортежа, а `nba.size` возвращает общее количество значений в наборе данных. В это значение включаются и отсутствующие (пустые) значения. Получить распределение не пустых значений по столбцам можно используя `nba.count()`, а общее количество значений пожно получить вызвав `nba.size`.
